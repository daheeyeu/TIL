# 캐시(Cache)

> 자주 사용하는 데이터나 값을 미리 복사해 놓는 임시 장소
> 

아래와 같은 저장공간 계층 구조에서 확인할 수 있듯이, 캐시는 저장 공간이 작고 비용이 비싼 대신 빠른 성능을 제공한다.
Cache는 아래와 같은 경우에 사용하면 좋다.

- 반복적으로 동일한 결과를 돌려주는 경우(이미지나 썸네일)
- Cache 접근시간에 비해 원래 데이터에 접근하는 시간이 오래걸리는 경우(서버의 균일한 API데이터)

Cache란 반복적으로 데이터를 불러오는 경우에, DBMS 혹은 서버에 요청하는 것이 아니라

Memory에 데이터를 저장하였다가 불러다 쓰는 것

을 의미한다. Enterprise급 Application에서는 DBMS의 부하를 줄이고, 성능을 높이기 위해 캐시(Cache)를 사용한다. 원하는 데이터가 캐시에 존재할 경우 해당 데이터를 반환하며, 이러한 상황을 Cache Hit라고 한다. 하지만 원하는 데이터가 캐시에 존재하지 않을 경우 DBMS 또는 서버에 요청을 해야하며 이를 Cache Miss라고 한다. 캐시는 저장공간이 작기 때문에, 지속적으로 Cache Miss가 발생하는 데이터의 경우 캐시 전략에 따라서 저장중인 데이터를 변경해야 한다.
# 캐시(Cache)의 등장

Cache란 나중에 요청할 결과를 미리 저장해둔 후 빠르게 서비스 해주는 것을 의미한다. 즉, 미리 결과를 저장하고 나중에 요청이 오면 그 요청에 대해서 DB 또는 API를 참조하지 않고 Cache를 접근하여 요청을 처리하게 된. 이러한 cache가 동작 할 수 있는 철학에는 파레토 법칙이라는 것이 있다.

**파레토 법칙이란 80퍼센트의 결과는 20퍼센트의 원인으로 인해 발생한다는 의미이다.**
즉, 이것은 Cache가 효율적일 수 있는 이유가 될 수 있다. 모든 결과를 캐싱할 필요는 없으며, 우리는 서비스를 할 때 많이 사용되는 20%를 캐싱한다면 전체적으로 영향을 주어 효율을 극대화 할 수 있다는 의미이다.

상위 20%의 요청만 캐시(Cache)를 사용해도 전체 80%리소스가 절감 될 것이고, 성능은 대폭 향상 될 것이다.

# 어떤 정보를 캐시(Cache)에 담는가?

모든 데이터를 캐시에 담기에는 캐시라는 저장 공간은 작다. 그렇기 때문에 파레토의 법칙에 해당하는 소수의 데이터를 선별해야한다. 이때 사용되는 것이 **지역성**이다.## 시간적 지역성

특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것을 말한다. 메모리 상의 같은 주소에 여러 차례 쓰기를 수행할 경우 상대적으로 작은 크기의 캐시를 사용해도 효율성을 꾀할 수 있다.

## 공간적 지역성

특정 데이터와 가까운 주소가 순서대로 접근되었을 경우를 공간적 지역성이라고 한다.CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져오게 된다. 이때 메모리 주소를 오름차순이나 내림차순으로 접근한다면, 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시의 효율성이 크게 향상된다.

## 순차 지역성

공간 지역성과 함꼐 설명되기도 한다. 데이터가 순차적으로 엑세스되는 경향을 보인다. 프로그램 내의 명령어가 순차적으로 구성된다.

## **캐시의 작동원리**

캐시메모리에는 "자주사용 하는 데이터"를 위치시켜야 유리하다는 것을 알수있다. 그러면 이 "자주사용 하는 데이터"는 어떻게 판단 할까?

"자주 사용하는 데이터"에 대한 판단은 지역성의 원리를 따른다. 지역성의 원리는 시간적 지역성(Temporal Locality)와 공간적 지역성(Spataial Locality)가 있다.

- 시간적 지역성(Temporal Locality)최근 접근한 데이터에 자주 접근하는 특성을 말한다.(점심시간에 카페에 아이스아메리카노를 찾는 현상이 높아지는 경우...)
- `int[] arr = new int[6]; for(int i=0; i<10; i++){ arr[i] = i+1 }`
- 예를 들면 for문의 인덱스 변수의 경우 짧은 시간에 여러번의 접근이 이루어진다.
- 공간적 지역성(Spatial Locality)최근 접근한 데이터의 주변 공간을 접근하는 특성을 말한다.컴퓨터는 메모리에서 데이터를 읽어올때, 메모리의 주소를 이용해 가져온다. 이때 해당 데이터만 가져오는 것이 아니라, 해당 데이터의 블록을 읽어오는 특성이 있다.
- (상사에게 자료보고시, 해당년도 자료외에도 3개년치 정도의 자료를 혹시 몰라서 가져갈때!....)
- arr이라는 int형 배열의 요소에 계속 접근하는 것을 볼수 있다.

# 캐시의 사용 구조1. Client로 부터 요청을 받는다.
2. Cache와 작업을 한다.
3. 실제 DB와 작업한다
4. 다시 Cache와 작업한다.

> cache는 일반적으로 위의 이미지와 같은 flow로 사용됩니다. 동일한 flow에서 어떻게 사용하냐에 따라서 look aside cache(Lazy Loading)와 write back으로 나뉜다.
> 
- look aside cache (Lazy Loading)
1. Cache에 Data 존재 유무 확인
2. Data가 있다면 cache의 Data 사용
3. Data가 없다면 cache의 실제 DB Data 사용
4. DB에서 가져온 Data를 Cache에 저장
    
    look aside cache는 캐시를 한번 접근하여 데이터가 있는지 판단한 후, 있다면 cache의 데이터를 사용하며 없다면 실제 DB 또는 API를 호출하는 로직으로 구현됩니다. 대부분의 cache를 사용한 개발이 해당 프로세스를 따르고 있다.
    
- write back
1. Data를 Cache에 저장
2. Cache에 있는 Data를 일정 기간동안 Check
3. 모여있는 Data를 DB에 저장
4. Cache에 있는 Data 삭제
    
    write back은 cache를 다르게 이용하는 방법이다. DB는 접근 횟수가 적을수록 전체 시스템의 퍼포먼스는 좋아진다. 데이터를 쓰거나 많은 데이터를 읽게되면 DB에서 Disk를 접근하게 된다. 이렇게 되면 Application의 속도 저하가 일어날 수 있다. 따라서 write back은 데이터를 cache에 모으고 일정한 주기 또는 일정한 크기가 되면 한번에 처리하는 것이다.
    

# 컴퓨터 공학에서 캐시란 어떤 의미로 쓰이는지?

"캐시"란

속도가 다른 두 장치 사이에서 속도차이를 메워주는 장치다.

모든 기기들의 데이터 전송 속도와 대역폭이 같다면, 매우 이상적이겠지만, 현실은 그렇지 않다. 이렇게 속도와 대역폭이 차이나는 기기들간의 속도를 조절해 주는 것이 캐시이다.

빠른 속도를 내는 기기에게는 미리 데이터를 준비함으로써 최적의 효율을 끌어내고, 느린 속도를 내는 기기에게는 처리할 데이터를 대신 받아 줌으로써, 다른 기기가 기다리는 일을 줄어들게끔 도와준다.

예를 들어보자. 데이터처리속도가 100MB/s인 메모리와, 1MB/s인 하드디스크가 있다. 이때 용량이 50MB인 데이터를 디스크에서 읽어와야할 상황이 생겼다. 메모리는 0.5초에처리 할것을, 하드디스크는 50초의 시간을 사용해야 하며, 이후 디스크로부터 메모리가 읽는시간0.5까지 추가로 발생한다. 이런 현상을 극복하기 위해 캐시(Cache)라는 장치가 탄생했다.

만약 메모리의 특정 영역을 캐시하고, 위의 상황에서 50MB중 30MB가 캐시되어있었다면, 20MB만 하드디스크에서 읽어오면 되고, 시간은 20초로 줄어든다. (데이터를 미리준비)
